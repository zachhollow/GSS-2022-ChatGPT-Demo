{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c09f1f2-1396-4d5e-ae35-a6ffa1eb9556",
   "metadata": {},
   "source": [
    "# AI Demo - Set Up Instructions\n",
    "##### Run the first two commands in Terminal, Bash or Command Prompt\n",
    "\n",
    "## Virtual Environment Setup (Optional)\n",
    "\n",
    "`python -m venv openai-env`\n",
    "\n",
    "## Activation\n",
    "\n",
    "- Windows: `openai-env\\Scripts\\activate`\n",
    "- MacOS or Unix: `source openai-env/bin/activate`\n",
    "\n",
    "If done correctly, you terminal should see `(openai-env)` in your terminal and you can select it as a Kernel moving forward.\n",
    "\n",
    "## API Key Setup\n",
    "\n",
    "Follow the steps in the Quickstart Guide to set up your API key.\n",
    "\n",
    "You can also do the following \n",
    "\n",
    "+ Navigate to your project folder `cd ~/Desktop/source/my-project`\n",
    "\n",
    "+ Create an .env file `touch .env`\n",
    "\n",
    "+ \n",
    "\n",
    "\n",
    "\n",
    "## Documentation\n",
    "\n",
    "- OpenAI Documentation: https://platform.openai.com/docs/introduction\n",
    "- OpenAI API Reference: https://platform.openai.com/docs/api-reference\n",
    "\n",
    "## Libraries: \n",
    "- ```pip install --upgrade openai```\n",
    "- ```pip install pyreadstat```\n",
    "- ```pip install pandas```\n",
    "- ```pip install urllib3```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5491bcae-caf9-40b1-a2e1-232bf996672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame imported successfully.\n",
      "\n",
      "Here is a preview:\n",
      "\n",
      "   ABANY  ABDEFECT  ABFELEGL  ABHELP1  ABHELP2  ABHELP3  ABHELP4  ABHLTH  \\\n",
      "0    2.0       1.0       NaN      1.0      1.0      1.0      1.0     1.0   \n",
      "1    1.0       1.0       3.0      2.0      2.0      2.0      2.0     1.0   \n",
      "2    NaN       NaN       NaN      1.0      2.0      1.0      1.0     NaN   \n",
      "3    NaN       NaN       1.0      1.0      1.0      1.0      1.0     NaN   \n",
      "4    2.0       1.0       NaN      2.0      2.0      2.0      1.0     1.0   \n",
      "\n",
      "   ABINSPAY  ABMEDGOV1  ...  XMARSEX  XMARSEX1  XMOVIE  XNORCSIZ    YEAR  \\\n",
      "0       1.0        2.0  ...      1.0       1.0     NaN       6.0  2018.0   \n",
      "1       2.0        NaN  ...      1.0       NaN     2.0       6.0  2018.0   \n",
      "2       2.0        1.0  ...      NaN       1.0     2.0       6.0  2018.0   \n",
      "3       1.0        NaN  ...      NaN       NaN     2.0       6.0  2018.0   \n",
      "4       2.0        NaN  ...      1.0       NaN     2.0       6.0  2018.0   \n",
      "\n",
      "   YEARSJOB  YEARSUSA  YEARVAL  YOUSUP  ZODIAC  \n",
      "0       1.0       NaN      NaN    45.0     6.0  \n",
      "1       NaN       NaN      NaN     NaN    11.0  \n",
      "2      15.0       NaN      NaN     3.0     1.0  \n",
      "3      25.0       NaN      NaN    10.0     1.0  \n",
      "4       NaN       NaN      NaN     NaN     4.0  \n",
      "\n",
      "[5 rows x 1065 columns]\n",
      "\n",
      "Number of variables: 1065\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pyreadstat\n",
    "import urllib.request\n",
    "\n",
    "# Correct raw URL from GitHub\n",
    "url = \"https://github.com/zachhollow/GSS-2022-ChatGPT-Demo/raw/bfdacca0d979b272356c3b31638c219f808e8ea6/ReplicationData/GSS2018.sav\"\n",
    "local_file = \"GSS2018.sav\"\n",
    "\n",
    "# Download the file locally\n",
    "urllib.request.urlretrieve(url, local_file)\n",
    "\n",
    "# Use pyreadstat to read the SPSS file\n",
    "df, meta = pyreadstat.read_sav(local_file)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(\"DataFrame imported successfully.\\n\\nHere is a preview:\\n\")\n",
    "print(df.head())\n",
    "\n",
    "# Preview total number of variables \n",
    "count = len(meta.column_names)\n",
    "print(f\"\\nNumber of variables: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7caa46-9d0f-4284-b15d-c12315f4f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "#Capture all column names and labels saved as meta\n",
    "print(\"The full list of column names and labels:\\n\")\n",
    "for i in range(len(meta.column_names)):\n",
    "    var_name = meta.column_names[i]\n",
    "    var_label = meta.column_labels[i]\n",
    "    print(f\"{var_name}: {var_label}\")\n",
    "    \n",
    "# Uncomment the line below to print each variable name and label\n",
    "# print(captured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf44c3ff-ee8e-47df-83c0-5eafc8e4ea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been converted and saved to GSS2018.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert our SPSS file to a CSV as it's more compatible with Code Interpreter.\n",
    "csv_file_path = \"GSS2018.csv\"\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "print(f\"File has been converted and saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32915e76-6ec3-4c05-a0d7-bed1307ecc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Effectively need to add CRUD\n",
    "client = OpenAI()\n",
    "\n",
    "file = client.files.create(\n",
    "                file=open(f\"{csv_file_path}.csv\", \"rb\"),\n",
    "                purpose='assistants',\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03960c13-e8c4-45c1-9ed1-182620e41d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.retrieve(\"file-x6YV6lMHUF44eC03mKiVVR56\")\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a data analyst. Summarize data and provide data visualizations.\",\n",
    "    name=\"Data Analyst\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"file_search\"}], \n",
    "    model=\"gpt-4-turbo\",\\\n",
    "    tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [file.id]\n",
    "    }\n",
    "  }\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=input(\"\\nYou: \") \n",
    ")\n",
    "\n",
    "# First, we create a EventHandler class to define\n",
    "# how we want to handle the events in the response stream.\n",
    " \n",
    "class EventHandler(AssistantEventHandler):    \n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nAssistant > \", end=\"\", flush=True)\n",
    "      \n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nAssistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\nOutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    " \n",
    "# Then, we use the `stream` SDK helper \n",
    "# with the `EventHandler` class to create the Run \n",
    "# and stream the response.\n",
    " \n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Zach. The user has a background in data analytics and machine learning using Python.\",\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()\n",
    "\n",
    "\n",
    "image_data = client.files.content(\"file-x6YV6lMHUF44eC03mKiVVR56\")\n",
    "image_data_bytes = image_data.read()\n",
    "\n",
    "with open(\"./my-image.png\", \"wb\") as file:\n",
    "    file.write(image_data_bytes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (openai-env)",
   "language": "python",
   "name": "openai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
